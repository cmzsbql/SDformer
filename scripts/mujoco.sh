python train_vq.py --batch-size 128 --width 512 --lr 1e-4 --total-iter 200000 --lr-scheduler 200000 --code-dim 512 --nb-code 512 --down-t 2 --depth 3 --dilation-growth-rate 3 --out-dir ./output/output_mujoco --dataname mujoco --vq-act relu --quantizer ema_reset_sim --exp-name VQVAE --window-size 24 --commit 0.5 --gpu 0
python train_sdformer_ar.py --exp-name ARTM --batch-size 1024 --num-layers 1 --embed-dim-gpt 1024 --width 512 --code-dim 512 --nb-code 512 --n-head-gpt 16 --block-size 6 --ff-rate 4 --drop-out-rate 0.1 --resume-pth ./output/output_mujoco/VQVAE/net_best_ds.pth --vq-name VQVAE --out-dir ./output/output_mujoco/ --total-iter 62500 --lr-scheduler 150000 --lr 0.0008 --dataname mujoco --down-t 2 --depth 3 --quantizer ema_reset_sim --eval-iter 2500 --print-iter 500 --pkeep 0.9 --dilation-growth-rate 3 --vq-act relu --window-size 24 --gpu 0
